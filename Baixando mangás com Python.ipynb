{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando mangás com Python\n",
    "\n",
    "Alvo: centraldemangas.org\n",
    "Mangá Inicial: One Piece\n",
    "Ferramentas que vamos usar:\n",
    "\n",
    "- editor de texto (sublime text3)\n",
    "- terminal\n",
    "- Python3\n",
    "    - argparse\n",
    "    - os\n",
    "    - time\n",
    "    - urllib.request\n",
    "    - BeautifulSoup\n",
    "    \n",
    "### Porque fazer isso?\n",
    "Bom, primeiro porque parece ser legal :)\n",
    "Segundo porque essa que parece ser uma tarefa simples, pode acabar se tornando um pouco complexa, envolvendo alguns conceitos que podem ser desconhecidos numa primeira vez, mas que trazem um grande aprendizado.\n",
    "\n",
    "O workflow é muito simples: vamos dizer para o programa qual o capítulo queremos baixar.\n",
    "Agora vamos falar um pouco, mas bem rápido sobre as ferramentas que vamos usar.\n",
    "\n",
    "### Standard libraries\n",
    "- argparse\n",
    "    - O módulo argparse é usado para criar CLIs de maneira fácil e amigável.\n",
    "- os\n",
    "    - Esse módulo fornece uma maneira portável de usar funcionalidade do sistema operacional.\n",
    "- time\n",
    "    - Funções realacionadas ao tempo.\n",
    "- urllib.request\n",
    "    - Esse módulo define funções e classes que ajudam a \"abrir\" e \"ler\" URLs (maioria HTTP).\n",
    "- BeautifulSoup\n",
    "    - É uma biblioteca escrita em Python projetada para parsear páginas.\n",
    "\n",
    "Bom, vamos deixar de papo e começar a programWAIT! Antes disso precisamos fazer uma coisa.\n",
    "\n",
    "### Preparar o ambiente\n",
    "Iremos isolar nosso ambiente do resto do sistema, para podermos instalar todas as dependências do projeto de maneira segura.\n",
    "````shell\n",
    "$ mkvirtualenv -p python3 pymanga\n",
    "$ pip install beautifulsoup4\n",
    "````\n",
    "\n",
    "Preparado nosso ambiente, e instalada nossas dependências, agora sim vamos iniciar a programação :)\n",
    "\n",
    "### 1ª etapa - Função `main()`\n",
    "````python\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog='PyManga',\n",
    "        description='An easily way to download your favorite mangas'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-m', '--manga',\n",
    "        type=str, help=\"Type the manga's name\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-c', '--chapter',\n",
    "        type=str, help='Type the chapter you wish'\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.manga and args.chapter:\n",
    "        download_chapter(args.chapter)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ª etapa - Função `create_folder()`\n",
    "\n",
    "````python\n",
    "def create_folder(chapter):\n",
    "    folder = 'capitulo-{}'.format(chapter)\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "        return folder\n",
    "    except OSError:\n",
    "        print('Diretório já existente')\n",
    "        return folder\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3ª etapa - Função `download_chapter()`\n",
    "````python\n",
    "BASE_URL_ONE_PIECE = 'http://mangaop.info/capitulos/{}#1'\n",
    "\n",
    "def download_chapter(chapter):\n",
    "    url = BASE_URL_ONE_PIECE.format(chapter)\n",
    "    req = urllib.request.Request(url)\n",
    "    content = urllib.request.urlopen(req).read()\n",
    "````\n",
    "O que nós fizemos até o momento, foi ajustar a nossa URL com o capítulo do mangá que o usuário quer baixar, usando o método `format()` da classe string. \n",
    "Depois disso, nós criamos um objeto `Request` usando a url como parâmetro. Após isso, usamos este objeto como parâmetro para a função `urlopen()` que de fato abre uma conexão e captura a página. O método `read()` retorna conteúdo deste objeto.\n",
    "\n",
    "````python\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "````\n",
    "Tendo o html da página, agora nós criamos um objeto BeautifulSoup, usando o `html.parser` como parser. Agora, antes de seguir para o passo seguinte, vale dar uma olhada no html. Primeiramente nota-se que o HTML gerado no navegador é **muito** diferente do HTML que a requisição retorna. Um dos motivos é que essa requisição feita pelo Python, não tem como executar os códigos JS contidos na páginas, que depois de carregados podem e alteram o DOM da página. \n",
    "\n",
    "Sendo assim, tive que analisar o HTML para ver como faria para capturar o que eu quero. Após finalizar esta análise, pude notar que a URL da imagem do capítulo estava dentro de uma variável de um código JS, ou seja, dentro de uma tag `<script>`. Bom, aqui veio o pulo do gato:\n",
    "````python\n",
    "    words = soup.findAll('script')[16].string.split()\n",
    "````\n",
    "O método `findAll()` me retorna uma lista com todas as ocorrências da tag que eu passar como parâmetro. Após isso eu notei que a script que estava no índice 16 era o que continha a variável com a URL que eu queria. Então uso o atributo `string` que me retorna o toda a tag, inclusive seu conteúdo, como texto, e dei um `split()`, que retorna uma lista com as palavras naquela string, usando como separador o espaço entre as palavras.\n",
    "````python\n",
    "manga_url = ''\n",
    "    for word in words:\n",
    "        # check if word contains 'http' string\n",
    "        if 'http' in word:\n",
    "            # if so, assign it to manga_url and break the for\n",
    "            manga_url = word\n",
    "            break\n",
    "````\n",
    "Sendo assim, minha solução é: percorrer a lista e verificar se naquele item da lista há a string `http`. Se houver, este será a URL da imagem, uma vez que dentro deste script só há este único link. Porém, ele retorna o link como está no código, com aspas duplas (e.g. `\"http://google.com\"`).\n",
    "````python\n",
    "    manga_url = manga_url.replace('\"', '')\n",
    "````\n",
    "Antes de continuar, vamos expôr algumas informações. O plano é baixar todas as imagens daquele capítulo. Eu pude notar que as imagens seguem um padrão. Digamos que estejamos com o capítulo 809 em questão, este padrão seria o seguinte:\n",
    "* imagem 1: http://mangas2016.centraldemangas.com.br/one_piece/one_piece809-01.jpg\n",
    "* imagem 2: http://mangas2016.centraldemangas.com.br/one_piece/one_piece809-02.jpg\n",
    "Porém a URL que pegamos lá da tag `<script>`, é a seguinte:\n",
    "* URL: http://mangas2016.centraldemangas.com.br/one_piece/one_piece809\n",
    "\n",
    "Sendo assim, o que eu preciso fazer para pegar todas as imagens deste capítulo, é saber quantas páginas ela tem.\n",
    "````python\n",
    "    number_img = int(soup.find('select', id='capPages').text.split()[-1:][0])\n",
    "````\n",
    "Eu capturo a tag `<select>` que contém as opções com os números de imagens, uso o atributo `text` que me retorna o os `value` das tags `<option>` desse `<select>`, pego o último valor e o converto para `int`. Pronto, tenho a quantidade de imagens que esse capítulo tem. Agora vamos começar o processo de baixar as imagens.\n",
    "````python\n",
    "    folder = create_folder(chapter)\n",
    "    for i in range(1, number_img+1):\n",
    "        url = manga_url+'-{}.jpg'.format(i)\n",
    "        filename = 'capitulo-{}.jpg'.format(i)\n",
    "\n",
    "        print(url) # apenas para sabermos a URL que será usada\n",
    "        req = urllib.request.Request(url)\n",
    "        content = urllib.request.urlopen(req)\n",
    "        \n",
    "        with open(os.path.join(folder, filename), 'wb') as f:\n",
    "            f.write(content.read())\n",
    "            print('Arquivo salvo com sucesso! - {}'.format(filename))\n",
    "    return\n",
    "````\n",
    "Nós percorremos com o for de 1 até a última imagem, e adicionamos ao final da imagem o número da imagem em questão, para completar a URL da imagem (como no exemplo lá de cima). Construída a URL, crio um `Request` mais uma vez, e uso no `urlopen()`. Após crio o arquivo que será salvo no caminho da pasta que criamos anteriormente (antes de iniciar o loop).\n",
    "\n",
    "Pronto, teoricamente já finalizamos nossa função para baixar a imagem, e salvá-la como um arquivo na nossa máquina. Agora para começarmos a usar nosso script, basta um pequeno detalhe:\n",
    "````python\n",
    "    if __name__ == '__main__':\n",
    "        main()\n",
    "````\n",
    "Dessa maneira, quando executarmos o script, ele vai chamar a função `main()` que é a responsável por pegar os valores passados pela linha de comando.\n",
    "\n",
    "Vamos testar o programa! Vou baixar o capítulo 725\n",
    "\n",
    "`python pymanga.py -m \"One Piece\" -c 725`\n",
    "\n",
    "No terminal, você vai ver o seguinte:\n",
    "````shell\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-1.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-1.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-2.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-2.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-3.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-3.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-4.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-4.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-5.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-5.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-6.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-6.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-7.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-7.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-8.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-8.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-9.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-9.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-10.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-10.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-11.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-11.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-12.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-12.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-13.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-13.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-14.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-14.jpg\n",
    "http://mangas2013.centraldemangas.com.br/one_piece/one_piece725-15.jpg\n",
    "Arquivo salvo com sucesso! - capitulo-15.jpg\n",
    "````\n",
    "\n",
    "Você vai notar que no mesmo diretório onde você salvou o arquivo pymanga.py, estará uma pasta `capitulo-725`, que é onde as imagens estarão salvas. Vamos visualizá-las...\n",
    "\n",
    "Epa, parece que algo deu errado, não foi? Bom, a primeira coisa que estranhei a primeira vez foi o tamanho da imagem. Baixando ela pelo navegador, fica uns `300kB`, mas ali temos várias imagens com `39,1kB`. E ao tentar visualizar a imagem, o visualizador padrão do seu sistema não vai mostrar imagem nenhuma. O que deu errado? Se você for no site e pegar a URL da imagem, vai ver que as imagens iniciais tem a URL com final `one_piece725-01.jpg` ao invés de `one_piece725-1.jpg`. Ou seja, o que acontece é que estamos requisitando uma imagem que não existe, e quando não existe, ele redireciona para a home centraldemangas.org, baixa esse HTML e salva como imagem.\n",
    "\n",
    "### Tratando das possibilidades dos erros\n",
    "Enquanto eu desenvolvia este sistema, me deparei com diversas situações e problemas. Vou listar alguns deles:\n",
    "\n",
    "- Redirect quando o arquivo não existe\n",
    "- Final da URL errada\n",
    "- Conexão negada por causa do header\n",
    "- Conexão negada por múltiplas requisições do mesmo IP numa faixa de tempo\n",
    "- host errado para o servidor\n",
    "\n",
    "Aquele arquivo nada mais é do que: uma página HTML. Se você renomear o final da extensão de `.jpg` para `.html`, poderá ver seu conteúdo, que será a home do site centraldemangas.org.\n",
    "\n",
    "Como tratar esse problema?\n",
    "\n",
    "### Criando nosso arquivo header\n",
    "````python\n",
    "# arquivo config.py\n",
    "HEADER_ONE_PIECE = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:42.0) Gecko/20100101 \\\n",
    "                   Firefox/42.0',\n",
    "    'Host': 'mangas2014.centraldemangas.com.br',\n",
    "    'Accept': 'image/png,image/*;q=0.8,*/*;q=0.5',\n",
    "    'Accept-Language': 'pt-BR,en;q=0.5',\n",
    "    'Referer': 'http://mangaop.info/capitulos/747'\n",
    "}\n",
    "````\n",
    "\n",
    "### Otimizando nosso código\n",
    "````python\n",
    "# o import abaixo deve ir para o início do arquivo\n",
    "from configs import HEADER_ONE_PIECE\n",
    "\n",
    "    folder = create_folder(chapter)\n",
    "    for i in range(1, number_img+1):\n",
    "        time.sleep(3) # aguarda 3s entre cada requisição\n",
    "\n",
    "        print(url) # apenas para sabermos a URL que será usada\n",
    "        req = urllib.request.Request(url)\n",
    "        content = urllib.request.urlopen(req)\n",
    "        \n",
    "        # Esse é o pulo do gato para evitar o final da URL errada\n",
    "        if i in range(1, 10):\n",
    "            final = '0'+str(i)\n",
    "            url = manga_url+'-{}.jpg'.format(final)\n",
    "            filename = 'capitulo-{}.jpg'.format(final)\n",
    "        else:\n",
    "            url = manga_url+'-{}.jpg'.format(i)\n",
    "            filename = 'capitulo-{}.jpg'.format(i)\n",
    "        \n",
    "        try:\n",
    "            # abaixo faremos uso da variável com infos do header para esse site\n",
    "            regex = re.compile('(^http:\\/\\/.*\\.centraldemangas\\.com\\.br)')\n",
    "            host = regex.search(url).group()\n",
    "            HEADER_ONE_PIECE.update(host=host)\n",
    "            print('host:', HEADER_ONE_PIECE['host'])\n",
    "            req = urllib.request.Request(url, headers=HEADER_ONE_PIECE)\n",
    "            # print(url) ativar esse print caso queira ver a URL da imagem no terminal\n",
    "            content = urllib.request.urlopen(req)\n",
    "        except urllib.error.HTTPError:\n",
    "            print('Arquivo {} indisponível'.format(filename))\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(folder, filename), 'wb') as f:\n",
    "            f.write(content.read())\n",
    "            print('Arquivo salvo com sucesso! - {}'.format(filename))\n",
    "    return\n",
    "````\n",
    "\n",
    "##### to-do explicar o que se passa no código acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
